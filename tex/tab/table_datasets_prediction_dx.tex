\begin{table}
\centering
\caption{
Experiment of diagnosis classification.
Classification accuracy (the higher the better) from a 5-folds cross-validation experiments is shown.
On average, in-dataset (same) prediction performance is higher with respect to all other cases.
Out-dataset prediction performance is higher if multiple dataset are pooled together (leave out test) with respect to the 
average case where our model is trained with a single dataset (different).
}
\begin{tabular}{llcr}
\toprule
       &      &            \multicolumn{2}{c}{\% accuracy} \\
test dataset & train dataset & mean & std \\
\midrule
adni1  & same            &  61.22 & 5.11 \\
       & different (avg) &  49.43 & 11.56 \\
       & leave out test  &  58.38 & 3.78 \\
\midrule
adni2  & same            &  64.28 & 0.98 \\
       & different (avg) &  46.41 & 5.20 \\
       & leave out test  &  56.95 & 3.11 \\
\midrule
miriad & same            &  90.99 & 8.48 \\
       & different (avg) &  76.45 & 13.07 \\
       & leave out test  &  92.42 & 9.42 \\
\midrule
oasis3 & same            &  80.19 & 4.95 \\
       & different (avg) &  54.34 & 9.32 \\
       & leave out test  &  62.45 & 7.01 \\
\midrule
local  & same            &  76.85 & 4.41 \\
       & different (avg) &  34.12 & 13.13 \\
       & leave out test  &  38.16 & 5.41 \\
\midrule
\midrule
average& same            &  \textbf{74.70} & 4.79 \\
       & different (avg) &  52.15 & 10.46 \\
       & leave out test  &  61.67 & 5.75 \\
\bottomrule
\end{tabular}
\end{table}
