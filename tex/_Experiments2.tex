%%%%%%%%%%%%%%%%%%%%%
%% MEDICAL IMAGING %%
%%%%%%%%%%%%%%%%%%%%%
\section{Experiments on Medical Imaging Datasets}
\label{sec:real}

% \input{./tex/tab/table_datasets_cross_validation.tex}
% \input{./tex/tab/table_datasets_prediction.tex}
% \input{./tex/tab/table_model_comparison.tex}

% Joint modeling of multiple datasets in real applications often represents an hybrid case between modeling missing at random (MAR) and missing not at random (MNAR) observations.
% Indeed, every dataset may lack of views which are instead present in others by default.
% At the same time, in each dataset, there may be missing views for some data-points due to unknown reasons.
% 
In this section we describe our results on jointly modeling real medical imaging datasets, independently acquired in the context of dementia studies.

We executed three kinds of experiments:
1) benchmark evaluation of our model against the best competing methods from the previous section;
2) multi-view feature prediction with our model on all the available datasets in multiple training and testing conditions.
3) diagnosis classification from multi-view heterogeneous data in different training and testing conditions.

\subsection{Data Sources}
\label{ssec:datasets}

Data used in the preparation of this section were obtained from the following sources.
\begin{enumerate}
%
\item The Alzheimer's Disease Neuroimaging Initiative (ADNI)
\footnote{
\href{http://adni.loni.usc.edu}{adni.loni.usc.edu}.
The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. For up-to-date information, see \href{www.adni-info.org}{www.adni-info.org}.
},
a database of brain imaging and related clinical data of cognitively normal subjects, and on patients presenting various degrees of cognitive decline.
%
\item MIRIAD dataset, a database of brain imaging and related clinical data of cognitively normal subjects and patients affected by Alzheimer's disease \citep{Miriad}.
%
\item OASIS-3 dataset, a database of brain imaging and related clinical data of cognitively normal subjects and subjects at various stages of cognitive decline \citep{oasis3}.
%
\item A local cohort collected at the Geneva University Hospitals, with brain imaging and related clinical data of patients with various cognitive disorders.
\end{enumerate}
Subjects enrollment, data collection, and data sharing were approved by the ethic committees associated to each study dataset in accordance with the principles of the Declaration of Helsinki.
% Each subject, or his/her legal tutor, provided a voluntary written informed consent for participation in the original studies.

The available imaging modalities comes from the following acquisitions:
%
\begin{enumerate}
\item structural Magnetic Resonance Imaging (MRI) to measure anatomical volumes in the brain;
%
\item Positron Emission Tomography (PET) with Fluorodeoxyglucose (FDG) tracer, to measure the glucose uptake, which reflects the functional status of the brain;
\item PET with the AV45 tracer, to measure the amyloid deposits in the brain;
\item PET with the AV1451 tracer, to measure the tau protein aggregates in the brain.
\end{enumerate}
%

We divided the ADNI dataset into two complementary datasets:
`Adni1', composed by subjects recruited in the initial ADNI1 study (2004-2009),
and `Adni2' composed by those subjects subsequently recruited in ADNI-GO, ADNI2, and ADNI3 (2010-ongoing).
Data modalities and acquisition protocols of `Adni1' present differences from those of `Adni2'.
Specifically, in `Adni1' and `Adni2' the MRI imaging was performed respectively on 1.5T and 3T scanners.
The two cohorts differs also for the presence of PET imaging data.
Therefore we consider these two cohorts as separated datasets.

To summarize, we grouped our data into five distinct datasets which we named as follows: `Adni1', `Adni2', `Miriad', `Oasis3', `Geneva'.

\subsection{Imaging Processing}
The brain scans were processed in order to have measurements on regions defined in the Desikan-Killiany atlas \citep{Desikan2006}.
Brain MRI scans were processed with FreeSurfer \footnote{\href{https://surfer.nmr.mgh.harvard.edu/}{surfer.nmr.mgh.harvard.edu}} \citep{freesurfer} to measure brain cortical and sub-cortical volumes, and volumes occupied by the cerebro-spinal fluid (CSF), for a total of $99$ regions of interest.
Relative standardized uptake values (SUVR) were computed for the PET scans (FDG, AV45, AV1451), processed with SPM \citep{Ashburner2000}.
SUVRs were computed using the cerebellum as reference region, and averaged in the same regions used for the MRI, except those containing the CSF, for a total of $94$ regions of interest.

\subsection{Gathering Observations into Views}
\label{ssec:views}
\input{./tex/tab/table_datasets_numbers.tex}

Observations from the five available datasets (\S~\ref{ssec:datasets}) were grouped into the following views.
\begin{enumerate}
\item clin: grouping age and the Mini-Mental cognitive score (MMSE).
\item MRI: grouping brain volumes computed with FreeSurfer.
\item FDG: average brain glucose uptake measured through the analysis of FDG-PET scans.
\item AV45: average brain amyloid deposits measured through the analysis of AV45-PET scans.
\item AV1451: average brain tau protein aggregates measured through the analysis of AV1451-PET scans.
\end{enumerate}

For each subject belonging to the `Adni1', `Adni2', 'Miriad' and `Geneva' datasets, we choose the first available time-point, or baseline.
In `oasis3', since measurements were mostly acquired in different days, we choose to pair nearby time points across modalities into a single one.
Time interval between views within one subject was minimal (AV45 vs MRI: $\leq 90$ days, MRI vs clin: $\leq 90$ days).

In \tabref{table:datasets} we show the number of observations stratified by dataset and view.
Size of the intersection ($\cap$) and union ($\cup$) of subjects with available views is also provided.
Please note that the only view in common across datasets is the clinical one, composed by MMSE and age features only.

We adjusted all the views feature-wise with \textit{ComBat} \citep{combat}, a normalization method originally develop in genomics, which has been adopted in neuroimaging studies to reduce unwanted sources of variation in the data due to the differences in acquisition protocols among datasets \citep{Fortin2017, Fortin2018, Orlhac2020}.
In ComBat, we set the variable `age' as main regressor, and `Adni2' as reference dataset for the training set.
The ComBat reference dataset for testing was the whole training split.

A final feature-wise standardization step was applied by zero centering the data and by rescaling them to have a unity variance.
Standardization parameters were computed on the training sets and applied to training and testing sets.

\subsection{Experiment 1: Benchmark Validation}
\input{./tex/tab/table_model_comparison.tex}

The purpose of this experiment is to validate on real data the benchmarked results obtained with the synthetic experiments (\S~\ref{sec:synth}).

As benchmark methods, we choose the best performers on the synthetic experiments, namely KNN5 and DAE.
We choose for our model a linear Gaussian parameterization for the likelihood and variational distributions of \eqnref{eq:decoder} and \eqnref{eq:dropout_posterior} respectively.

We trained all the models (KNN5, DAE, ours) with data coming from all the datasets except from `Adni2', left out for testing purposes.
We choose the `Adni2' dataset as testing dataset since it provides all the views, and the highest number of observations per view (\tabref{table:datasets}).

Prediction performances were evaluated with the Mean Squared Error (MSE) metric, measured on the available views in the testing dataset, reconstructed with \eqnref{eq:reconstruction}.
All results were validated by means of $5$-folds cross-validation.

\paragraph{Results}
In \tabref{tab:model_comparison}, we show the MSE metric on predicting missing views in the testing dataset with our model and with the benckmark ones.
Best results are in boldface, which show a clear advantage of using our model and confirm our findings in the synthetic experiments.

\subsection{Experiment 2: Feature Prediction}
\label{ssec:feats}
\input{./tex/tab/table_datasets_prediction_combat_couples.tex}
The purpose of this experiment is to compare, in features prediction experiments, the generalization performance the MCVAE model with respect to our new Multi Task extension (MT-MCVE).
This experiment was run in three different conditions:
%
\begin{enumerate}
\item Single Task with Internal Benchmark (STIB): when training and testing data are chosen from the same dataset;
%
\item Single Task with External Benchmark (STEB): when models trained on one dataset are tested on another one;
%
\item Multi Task Learning (MTL): when models are trained on all the available datasets except the testing one.
%
\end{enumerate}
%
In STIB and STEB experiments, both MCVAE and MT-MCVAE models are trained on the same views,
but while in MCVAE we need to discard observations with missing views from the training set,
with MT-MCVAE we can include them by grouping together observations with common views into homogeneous tasks.
In MTL experiments, MCVAE models cannot be trained because no observation has simultaneously all the views.
%By removing the cases where views are not simultaneously present in both the training and testing set,
%we are left with $16$ possible scenarios where all the three experimental conditions can be simultaneously tested an thus compared.

We choose for both MCVAE and MT-MCVAE a linear Gaussian parameterization for the likelihood and variational distributions as in \eqnref{eq:decoder} and \eqnref{eq:dropout_posterior} respectively.
Models were trained on all the available views in the training dataset. %, independently of their presence in the testing dataset.
Prediction performances were evaluated with the Mean Squared Error (MSE) metric, measured on the available views in the testing dataset, reconstructed with \eqnref{eq:reconstruction}.
All results were validated by means of $5$-folds cross-validation.

\input{./tex/tab/table_datasets_prediction_nl.tex}

\paragraph{Results}
In \tabref{tab:features} and \tabref{tab:features_mtl} we show the prediction error in terms of MSE for each test dataset and view, on the three experimental conditions described earlier.
In STIB and STEB cases \tabrefp{tab:features}, the MT-MCVAE model performs either similarly or statistically better than the MCVAE, especially in cases where the difference between the union and intersection set of observations is higher (cfr. \tabref{table:datasets}).
In the MTL scenario \tabrefp{tab:features_mtl} there are $12$ cases that could be fitted with MT-MCVAE only.
We measure an overall better performance of MTL with respect to STIB ($7/12$ of cases) and with respect to STEB ($10/12$ of cases).

\subsection{Experiment 3: Diagnosis Prediction}
\label{ssec:classifier}
\input{./tex/tab/table_datasets_prediction_dx_couples.tex}

The purpose of this experiment is to compare, in diagnosis prediction experiments, the generalization performance of the MCVAE model with respect to the MT-MCVAE,
in the three experimental conditions described earlier: STIB, STEB, and MTL.
%
Diagnostic classes are:
Alzheimer's disease (AD),
mild cognitive impairment (MCI),
normal cognition (NC).

For both MCVAE and MT-MCVAE we choose a linear Gaussian parameterization for the variational distributions as in \eqnref{eq:dropout_posterior}.
To adapt the models to this new classification experiment, we adopt as decoding function for the latent variable $\z$, the following Categorical likelihood:
\begin{align}
\label{eq:classifier}
\p{y_{d,n}|\z,\thetab} = \operatorname{Cat}\left(\mathbf{\pi}=\thetab\z\right),
\end{align}
where $y_{d,n}$ is the diagnosis associated to the data-point $n$ in the dataset $d$.
The probability vector $\mathbf{\pi}$ is a two dimensional vector representing the class probability for each of the three binary comparisons across the three diagnostic classes, namely AD \textit{vs} MCI, AD \textit{vs} NC, MCI \textit{vs} NC ,and is parametrized with a linear transformation of the latent $\z$ by the matrix $\thetab$.

Models were trained on all the available views in the training dataset, independently of their presence in the testing dataset.
Classes probabilities were inferred from the all the available views in the testing dataset with the following equation:
\begin{equation}\label{eq:reconstructiony}
\begin{aligned}
\hat{y}_{d,n} = \frac{1}{V_{d, n}} \sum_{w=1}^{V_{d, n}} \EE{q_{d,n,w}(\z)}{\p{y_{d,n}|\z,\thetab}}.
\end{aligned}
\end{equation}
We attributed to each subject the diagnostic class with the highest inferred probability.

The performance on test datasets was evaluated by measuring the classification accuracy (\%).
All results were validated by means of $5$-folds cross-validation.

\paragraph{Results}
In \tabref{tab:classifier} we show the classification accuracy of MCVAE and MT-MCVAE.
In STIB and STEB cases, the MT-MCVAE model performs either similarly or statistically better than the MCVAE.
There are $7$ cases in the MTL condition \tabrefp{tab:classifier_mtl} that could be fitted with the MT-MCVAE model only.
In all of them we measure a better performance with respect to the best STEB cases.

