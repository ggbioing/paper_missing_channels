% The abstract should briefly summarize the contents of the paper in
% 150--250 words.
% \keywords{First keyword  \and Second keyword \and Another keyword.}
The joint modeling of neuroimaging data across multiple cohorts, or datasets, requires to consistently analyze high-dimensional heterogeneous information in presence of often non-overlapping sets of modalities, or views, across data samples (e.g. imaging modalities, clinical scores, biological measurements).
From a statistical perspective, the integration of heterogeneous data from different cohorts is regularly associated with the problem of missing information across datasets, which can happen in two forms:
missing at random (MAR), when the absence of a view is unpredictable and does not depend on the dataset (e.g. data corruption);
missing not at random (MNAR), when a specific view is unnecessary and absent by design for a specific dataset.
%
In order to take advantage of the increased variability and sample size when pooling together observations from many cohorts
and, at the same time being transparent to the ubiquitous problem of missing information,
we propose here a multi-task generative latent-variable model where the common variability across datasets stems from the estimation of a shared latent representation across views.
Our formulation allows to retrieve a consistent latent representation common to all views and datasets, even in the presence of missing information.
%
Simulations on synthetic data show that our method is able to identify a common latent representation of multi-modal datasets, even when the compatibility across datasets is minimal.
%
When jointly analyzing multi-modal neuroimaging and clinical data from independent dementia studies, our model is able to mitigate the absence of modalities without having to discard any available information.
Moreover, the common latent representation inferred with our model can be used to define robust classification tasks gathering the combined information across different datasets.
