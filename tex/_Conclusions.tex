\section{Conclusions}
 We proposed a new latent variable generative model able to learn simultaneously from multiple datasets, even in the presence of non-overlapping views among all the datasets.
 The available overlaps between pairs of datasets allow the information to flow through all the views in the dataset pool.
 Since the learned view-specific parameters are shared among datasets, missing views can be automatically imputed for every dataset.
 The method is a coherent extension of classical variational generative models, making the trainig fast and scalable, also with the support of mini-batch.
 Being dataset agnostic, our method allows to integrate all the available data into a joint model, gathering  all the available information from multiple datasets at the same time.
