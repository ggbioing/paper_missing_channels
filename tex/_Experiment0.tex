\section{Proof of concept}
\label{sec:proof_of_concept}

In this section we describe our results on a simple experiment where we use our MT-MCVAE method to model the joint relationship between MRI and PET-FDG images when there are missing data at train time.

Data comes from the `Adni2' dataset (\S~\ref{ssec:datasets}, \tabref{table:datasets}), from where we took the MRI and FDG modalities, and for each subject ($n=424$, with both MRI and FDG) we extracted $3$ brain slices for each one of the sagittal, coronal, and axial plane.
The resulting $3816$ slices were randomly allocated to a training and testing set with respectively sizes of $3500\backslash 316$.
We down sampled the slices to $28 \times 28$ images ($784$ pixels) to make it compatible with MNIST \citep{mnist}, an imaging dataset popularly used for the benchmark of deep learning based methods.
%
To simulate a datasets with missing views, we controlled for the fraction of observation with complete views ($f$) in the training set:
this procedure is depicted in \figref{fig:nimg_scheme} where we show a small ($n=30$) training dataset created with $f=1/3$.
%
For our true experiments we took all the $3500$ training images and we randomly removed the MRI and FDG view until reaching values of $f \in \{0, 0.25, 0.5, 0.75, 1\}$.
We adopted a deep architecture with $4$ layers for both encoders and decoders, having ReLU activation functions and layer dimensions of $784-1024-1024-16$ in the encoding and $16-1024-1024-784$ in the decoding path,
an architecture inspired from those used by \cite{dcca1} and \cite{dcca2} for a similar task on the MNIST dataset.
We adopted a Gaussian likelihood for the decoders, with independent diagonal covariance parameters, and we trained our model with mini-batches of size $500$ for $3000$ epochs, after setting up the Adam optimizer with a learning rate of 0.001.
Training was repeated $5$ times, by changing the initialization random seed of the model parameters.

\input{./tex/fig/nimg.tex}
\input{./tex/tab/table_nimg.tex}
In \tabref{tab:nimg} we show the Mean Squared Error (MSE) and Negative Log-Likelihood (NLL) when predicting MRI from the FDG slices and \textit{vice versa} in the testing set.
We notice the immediate drop in the error metrics as soon as the parameter $f$ increases, which means that as the models are fed with more and more paired MRI and FDG data points in the trainig set, its predictions on the testing set becomes more precise.
%
In \figref{fig:nimg_test} is possible to visually inspect these predictions.

